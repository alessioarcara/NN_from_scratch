{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1749,
   "id": "0c3f90cd-532c-4694-9b4c-cdacc1c75f93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "\n",
    "def xavier_initilization(size_l, size_l1):\n",
    "    return np.random.randn(size_l, size_l1) * np.sqrt(1 / size_l1)\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1. / (1. + np.exp(-z))\n",
    "\n",
    "\n",
    "def dsigmoid(z):\n",
    "    s = sigmoid(z)\n",
    "    return s * (1. - s)\n",
    "\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "\n",
    "def drelu(z):\n",
    "    return np.where(z > 0, 1, 0)\n",
    "\n",
    "\n",
    "activations = { \"relu\": relu, \"sigmoid\": sigmoid }\n",
    "activation_derivs = {\"relu\": drelu, \"sigmoid\": dsigmoid }\n",
    "\n",
    "class Network:\n",
    "    def __init__(self, layers):\n",
    "        self.dim = [size for size, _ in layers]\n",
    "        self.act = [activation for _, activation in layers]\n",
    "        self.l = len(layers)\n",
    "        # the input layer doesn't have parameters\n",
    "        self.w = [xavier_initilization(self.dim[i], self.dim[i-1])\n",
    "                  for i in range(1, self.l)]\n",
    "        self.b = [np.zeros((self.dim[i], 1)) \n",
    "                  for i in range(1, self.l)]\n",
    "        \n",
    "    def __forward(self, x):\n",
    "        a = x\n",
    "        a_list = [x]\n",
    "        z_list = []\n",
    "        \n",
    "        for i in range(self.l - 1):\n",
    "            z = np.dot(self.w[i], a) + self.b[i]\n",
    "            z_list.append(z)\n",
    "            a = activations[self.act[i + 1]](z)\n",
    "            a_list.append(a)\n",
    "            \n",
    "        return a_list, z_list\n",
    "\n",
    "    def __backward(self, a, z, y):\n",
    "        m = y.shape[0]\n",
    "        \n",
    "        d = (a[-1] - y) * activation_derivs[self.act[-1]](z[-1]) # output error\n",
    "        dw = [np.dot(d, a[-2].T) / m]\n",
    "        db = [np.mean(d, axis=1, keepdims=True)]\n",
    "\n",
    "        for l in range(2, self.l):\n",
    "            d = np.dot(self.w[-l + 1].T, d) * activation_derivs[self.act[-l]](z[-l])\n",
    "            dw.insert(0, np.dot(d, a[-l - 1].T) / m)\n",
    "            db.insert(0, np.mean(d, axis=1, keepdims=True))\n",
    "            \n",
    "        return dw, db \n",
    "\n",
    "    def __update(self, X_batch, y_batch, lr):\n",
    "        a, z = self.__forward(X_batch)\n",
    "        dw, db = self.__backward(a, z, y_batch)\n",
    "        \n",
    "        for i in range(self.l - 1):\n",
    "            self.w[i] -= lr * dw[i]\n",
    "            self.b[i] -= lr * db[i]\n",
    "        \n",
    "    def fit(self, X, y, n_epochs, lr=1, mini_batch_size=32, test_data=None, verbose=False):\n",
    "        n = len(X)\n",
    "        indices = np.arange(n)\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            if verbose: self.print_params()\n",
    "            np.random.shuffle(indices)\n",
    "            mini_batch_indices = [indices[k:k+mini_batch_size] \n",
    "                                  for k in range(0, n, mini_batch_size)]\n",
    "            \n",
    "            for mini_batch_idx in mini_batch_indices:\n",
    "                X_batch = np.atleast_2d(X[mini_batch_idx]).T\n",
    "                y_batch = np.atleast_2d(y[mini_batch_idx]).T\n",
    "                self.__update(X_batch, y_batch, lr)\n",
    "            \n",
    "            if test_data:\n",
    "                print(f\"Epoch {epoch}: Accuracy = {self.__evaluate(test_data)}\")\n",
    "            \n",
    "    def predict(self, X):\n",
    "        X = np.atleast_2d(X).T\n",
    "        a, _ = self.__forward(X)\n",
    "        return a[-1] \n",
    "    \n",
    "    def __evaluate(self, test_data):\n",
    "        test_results = [(np.argmax(self.predict(X)), y)\n",
    "                       for (X, y) in test_data]\n",
    "        return sum(int(y_pred == y) for (y_pred, y) in test_results) / len(test_results)\n",
    "    \n",
    "    def print_params(self):\n",
    "        print(\"----------------------------\")\n",
    "        print(\"Network Parameters:\")\n",
    "        print(\"----------------------------\")\n",
    "\n",
    "        for i, (w, b) in enumerate(zip(self.w, self.b)):\n",
    "            print(f\"Layer {i+1}:\")\n",
    "            print(\"Weights:\")\n",
    "            print(w)\n",
    "            print(f\"Shape: {w.shape}\")\n",
    "            print(\"Biases:\")\n",
    "            print(b.reshape(-1, 1))  # Reshape biases to be a column vector\n",
    "            print(f\"Shape: {b.shape}\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "        print(\"----------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1750,
   "id": "39d9a902-fbf2-40b0-8f2f-d70231113087",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "train_inputs = x_train.reshape(60000, 28*28)\n",
    "train_results = to_categorical(y_train, 10)\n",
    "test_inputs = x_test.reshape(10000, 28*28)\n",
    "test_data = list(zip(test_inputs, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1751,
   "id": "63c2639e-ffc3-4b05-aa76-9d787e6f0308",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_21284/838514860.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1. / (1. + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Accuracy = 0.777\n",
      "Epoch 1: Accuracy = 0.8336\n",
      "Epoch 2: Accuracy = 0.8392\n",
      "Epoch 3: Accuracy = 0.8579\n",
      "Epoch 4: Accuracy = 0.8704\n",
      "Epoch 5: Accuracy = 0.878\n",
      "Epoch 6: Accuracy = 0.8818\n",
      "Epoch 7: Accuracy = 0.8784\n",
      "Epoch 8: Accuracy = 0.8736\n",
      "Epoch 9: Accuracy = 0.8949\n",
      "Epoch 10: Accuracy = 0.8891\n",
      "Epoch 11: Accuracy = 0.8944\n",
      "Epoch 12: Accuracy = 0.8955\n",
      "Epoch 13: Accuracy = 0.8839\n",
      "Epoch 14: Accuracy = 0.8993\n",
      "Epoch 15: Accuracy = 0.9008\n",
      "Epoch 16: Accuracy = 0.8991\n",
      "Epoch 17: Accuracy = 0.8993\n",
      "Epoch 18: Accuracy = 0.9004\n",
      "Epoch 19: Accuracy = 0.9065\n",
      "Epoch 20: Accuracy = 0.9064\n",
      "Epoch 21: Accuracy = 0.9063\n",
      "Epoch 22: Accuracy = 0.9046\n",
      "Epoch 23: Accuracy = 0.9083\n",
      "Epoch 24: Accuracy = 0.8987\n",
      "Epoch 25: Accuracy = 0.9067\n",
      "Epoch 26: Accuracy = 0.9077\n",
      "Epoch 27: Accuracy = 0.9166\n",
      "Epoch 28: Accuracy = 0.912\n",
      "Epoch 29: Accuracy = 0.9084\n",
      "Epoch 30: Accuracy = 0.9121\n",
      "Epoch 31: Accuracy = 0.9181\n",
      "Epoch 32: Accuracy = 0.9109\n",
      "Epoch 33: Accuracy = 0.9095\n",
      "Epoch 34: Accuracy = 0.9136\n",
      "Epoch 35: Accuracy = 0.9113\n",
      "Epoch 36: Accuracy = 0.91\n",
      "Epoch 37: Accuracy = 0.9075\n",
      "Epoch 38: Accuracy = 0.9157\n",
      "Epoch 39: Accuracy = 0.9122\n",
      "Epoch 40: Accuracy = 0.9125\n",
      "Epoch 41: Accuracy = 0.9112\n",
      "Epoch 42: Accuracy = 0.9137\n",
      "Epoch 43: Accuracy = 0.9199\n",
      "Epoch 44: Accuracy = 0.9175\n",
      "Epoch 45: Accuracy = 0.9192\n",
      "Epoch 46: Accuracy = 0.9245\n",
      "Epoch 47: Accuracy = 0.9171\n",
      "Epoch 48: Accuracy = 0.9179\n",
      "Epoch 49: Accuracy = 0.9138\n"
     ]
    }
   ],
   "source": [
    "net = Network([(784, \"\"), (28, \"sigmoid\"), (28, \"relu\"), (10, \"sigmoid\")])\n",
    "net.fit(train_inputs, train_results, 50, 0.01, 32, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1763,
   "id": "d65c6a10-0d54-4383-bd34-15aea5572c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: 0\n",
      "y_pred: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/_krd7pz16cx09cvjhgjzrjl00000gn/T/ipykernel_21284/838514860.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1. / (1. + np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "rnd_idx = random.randint(0, len(x_test))\n",
    "plt.imshow(x_test[rnd_idx], cmap='grey')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(f\"y_true: {y_test[rnd_idx]}\")\n",
    "print(f\"y_pred: {np.argmax(net.predict((x_test[rnd_idx].reshape(1, 28*28))))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0230a98-5876-4eab-bc0e-a4920d42885d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86edde5-2859-46af-995d-a6cc11fc3f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
